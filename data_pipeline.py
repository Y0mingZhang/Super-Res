# -*- coding: utf-8 -*-
"""VOC Data Pipeline Test Bench.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RF0mPHNbnRuxZQJzMWhRglPj8pvUwdIr
"""

import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import Dataset
import torchvision
from torchvision import transforms
import matplotlib.pyplot as plt
from tqdm import tqdm
import os
import shutil
import itertools

def get_dataset_mean_std(dataset):
    np_dataset = np.stack([img for img, _ in dataset])
    mean = [np_dataset[:,i].mean() for i in range(3)] 
    std = [np_dataset[:,i].std() for i in range(3)]

    norm = transforms.Normalize(mean, std, inplace=True)
    
    return np_dataset

class Norm_Dataset_Wrapper(Dataset):
    def __init__(self, dataset_lr, dataset_hr):
        self.lr = []
        self.hr = []
        tt = transforms.ToTensor()

        np_dataset = np.stack([img for img, _ in dataset_lr])
        mean = [np_dataset[:,i].mean() for i in range(3)] 
        std = [np_dataset[:,i].std() for i in range(3)]
        norm = transforms.Normalize(mean=mean, std=std, inplace=True)
        for img in np_dataset:
            self.lr.append(torch.FloatTensor(norm(tt(img.transpose(1,2,0)))))

        np_dataset = np.stack([img for img, _ in dataset_hr])
        mean = [np_dataset[:,i].mean() for i in range(3)] 
        std = [np_dataset[:,i].std() for i in range(3)]
        norm = transforms.Normalize(mean=mean, std=std, inplace=True)
        for img in np_dataset:
            self.hr.append(torch.FloatTensor(norm(tt(img.transpose(1,2,0)))))
    
    def __getitem__(self, i):
        return self.lr[i], self.hr[i]

    def __len__(self):
        return len(self.lr)


def get_loaders(args):
    # Use 4x downsampling to approximate blur
    if os.path.isdir(args.cache_dir) and not args.overwrite_cache:
        cache_dir = args.cache_dir

        data_train = torch.load(os.path.join(cache_dir, 'train_dataset.bin'))
        data_test =  torch.load(os.path.join(cache_dir, 'test_dataset.bin'))

    else:
        if os.path.isdir(args.cache_dir):
            shutil.rmtree(args.cache_dir)

        cache_dir = args.cache_dir
        os.mkdir(cache_dir)


        ToTensor = transforms.ToTensor()
        Squeeze = transforms.Lambda(lambda x: x.squeeze())

        """
        blur_transform = transforms.Compose([
                        transforms.CenterCrop(OG_SIZE),
                        transforms.Resize((BLURRED_SIZE,BLURRED_SIZE)),
                        ToTensor,
                        Squeeze
        ])
        """

        og_transform = transforms.Compose([
                        transforms.CenterCrop(256),
                        ToTensor,
                        Squeeze
        ])

        area_interpol = transforms.Lambda(lambda x: torch.nn.functional.interpolate(x, scale_factor=.25, mode='area'))
        Unsqueeze = transforms.Lambda(lambda x: x.unsqueeze(0))
        interpol = transforms.Compose([
                transforms.CenterCrop(256),
                ToTensor,
                Unsqueeze,
                area_interpol,
                Squeeze,
        ])

        data_train = Norm_Dataset_Wrapper(torchvision.datasets.VOCSegmentation('.', download=True, image_set='train', transform=interpol), 
                        torchvision.datasets.VOCSegmentation('.', download=True, image_set='train', transform=og_transform))

        data_test = Norm_Dataset_Wrapper(torchvision.datasets.VOCSegmentation('.', download=True, image_set='val', transform=interpol), 
                        torchvision.datasets.VOCSegmentation('.', download=True, image_set='val', transform=og_transform))


        torch.save(data_train, os.path.join(cache_dir, 'train_dataset.bin'))
        torch.save(data_test, os.path.join(cache_dir, 'test_dataset.bin'))

        
    train_loader = torch.utils.data.DataLoader(data_train, batch_size=args.batch_size, shuffle=True)
    test_loader = torch.utils.data.DataLoader(list(zip(data_test.lr[:1000], data_test.hr[:1000])), batch_size=args.batch_size, shuffle=True)
    val_loader = torch.utils.data.DataLoader(list(zip(data_test.lr[1000:], data_test.hr[1000:])), batch_size=args.batch_size, shuffle=True)
    
    return train_loader, test_loader, val_loader
