# -*- coding: utf-8 -*-
"""VOC Data Pipeline Test Bench.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RF0mPHNbnRuxZQJzMWhRglPj8pvUwdIr
"""

import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import torchvision
from torchvision import transforms
import matplotlib.pyplot as plt
from tqdm import tqdm
import os
import shutil

def get_loaders(args):
    # Use 4x downsampling to approximate blur
    if os.path.isdir(args.cache_dir) and not args.overwrite_cache:
        cache_dir = args.cache_dir

        data_train = torch.load(os.path.join(cache_dir, 'train_dataset.bin'))
        data_test =  torch.load(os.path.join(cache_dir, 'test_dataset.bin'))

    else:
        if os.path.isdir(args.cache_dir):
            shutil.rmtree(args.cache_dir)

        cache_dir = args.cache_dir
        os.mkdir(cache_dir)


        ToTensor = transforms.ToTensor()
        Squeeze = transforms.Lambda(lambda x: x.squeeze())

        """
        blur_transform = transforms.Compose([
                        transforms.CenterCrop(OG_SIZE),
                        transforms.Resize((BLURRED_SIZE,BLURRED_SIZE)),
                        ToTensor,
                        Squeeze
        ])
        """

        og_transform = transforms.Compose([
                        transforms.CenterCrop(256),
                        ToTensor,
                        Squeeze
        ])

        area_interpol = transforms.Lambda(lambda x: torch.nn.functional.interpolate(x, scale_factor=.25, mode='area'))
        Unsqueeze = transforms.Lambda(lambda x: x.unsqueeze(0))
        interpol = transforms.Compose([
                transforms.CenterCrop(256),
                ToTensor,
                Unsqueeze,
                area_interpol,
                Squeeze,
        ])

        # transforms.Normalize([0.2859], [0.3530]) # Normalize to zero mean and unit variance

        data_train = list(zip(torchvision.datasets.VOCSegmentation('.', download=True, image_set='train', transform=interpol, target_transform=interpol), 
                        torchvision.datasets.VOCSegmentation('.', download=True, image_set='train', transform=og_transform, target_transform=og_transform)))

        data_test = list(zip(torchvision.datasets.VOCSegmentation('.', download=True, image_set='val', transform=interpol, target_transform=interpol), 
                        torchvision.datasets.VOCSegmentation('.', download=True, image_set='val', transform=og_transform, target_transform=og_transform)))

        torch.save(data_train, os.path.join(cache_dir, 'train_dataset.bin'))
        torch.save(data_test, os.path.join(cache_dir, 'test_dataset.bin'))

        
    train_loader = torch.utils.data.DataLoader(data_train, batch_size=args.batch_size, shuffle=True)
    test_loader = torch.utils.data.DataLoader(data_test[:1000], batch_size=args.batch_size, shuffle=True)
    val_loader = torch.utils.data.DataLoader(data_test[1000:], batch_size=args.batch_size, shuffle=True)
    
    return train_loader, test_loader, val_loader
